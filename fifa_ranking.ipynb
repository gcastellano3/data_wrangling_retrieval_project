{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec21a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL and headers for the request\n",
    "url = \"https://www.transfermarkt.es/statistik/weltrangliste\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',\n",
    "  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "  'Accept-Language': 'es-ES,es;q=0.9',\n",
    "  'Referer': 'https://www.transfermarkt.es/'\n",
    "}\n",
    "\n",
    "# Make the initial request to get the page content\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Define the table class to locate the relevant data\n",
    "soup.find_all(class_='responsive-table')\n",
    "\n",
    "# Extract available dates from the dropdown menu\n",
    "select = soup.find(\"select\", {\"name\": \"datum\"})\n",
    "options = select.find_all(\"option\") if select else soup.find_all(\"option\")\n",
    "\n",
    "dates = [opt.get(\"value\") for opt in options if opt.get(\"value\")]\n",
    "\n",
    "# Filter dates for December only\n",
    "from datetime import datetime\n",
    "\n",
    "selected_dates = [\n",
    "    f for f in dates\n",
    "    if datetime.strptime(f, \"%Y-%m-%d\").month == 12\n",
    "]\n",
    "\n",
    "# Construct URLs for each selected date\n",
    "web_urls = [\n",
    "    f'https://www.transfermarkt.es/statistik/weltrangliste/statistik/stat/ajax/yw1/datum/{date}/plus/0/galerie/0'\n",
    "for date in selected_dates\n",
    "]\n",
    "\n",
    "# Generate paginated URLs\n",
    "pages = []\n",
    "\n",
    "for url in web_urls:\n",
    "    for pag in range(1, 8):\n",
    "        pages.append(f'{url}/page/{pag}')\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "years = []\n",
    "positions = []\n",
    "countries = []\n",
    "confeds = []\n",
    "points = []\n",
    "\n",
    "# Loop through each page and extract the relevant data\n",
    "for page in pages:\n",
    "    resp = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "    for row in soup.find_all(\"tr\"):\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) >= 4:\n",
    "            years.append(page.split(\"/datum/\")[1].split(\"-\")[0])\n",
    "            positions.append(tds[0].get_text(strip=True))\n",
    "            countries.append(tds[1].get_text(strip=True))\n",
    "            confeds.append(tds[2].get_text(strip=True))\n",
    "            points.append(tds[3].get_text(strip=True))\n",
    "\n",
    "# Additionally, extract data for the year 2022\n",
    "urls2022 = [\n",
    "    f'https://www.transfermarkt.es/statistik/weltrangliste/statistik/stat/ajax/yw1/datum/2022-10-06/plus/0/galerie/0/page/{pag}'\n",
    "    for pag in range(1, 8)\n",
    "]\n",
    "for page in urls2022:\n",
    "    resp = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "    for row in soup.find_all(\"tr\"):\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) >= 4:\n",
    "            years.append('2022')\n",
    "            positions.append(tds[0].get_text(strip=True))\n",
    "            countries.append(tds[1].get_text(strip=True))\n",
    "            confeds.append(tds[2].get_text(strip=True))\n",
    "            points.append(tds[3].get_text(strip=True))\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Year': years,\n",
    "    'Position': positions,\n",
    "    'Country': countries,\n",
    "    'Confederation': confeds,\n",
    "    'Points': points\n",
    "    })\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "import os\n",
    "\n",
    "project_dir = os.getcwd()\n",
    "csv_route = os.path.join(project_dir, \"fifa_ranking.csv\")\n",
    "df.to_csv(csv_route, index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
