{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e623a1e8",
   "metadata": {},
   "source": [
    "Scrapping data - Historical FIFA ranking by country and confederation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2e44d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec21a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL and headers for the request\n",
    "url = \"https://www.transfermarkt.es/statistik/weltrangliste\"\n",
    "\n",
    "payload = {}\n",
    "headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',\n",
    "  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "  'Accept-Language': 'es-ES,es;q=0.9',\n",
    "  'Referer': 'https://www.transfermarkt.es/'\n",
    "}\n",
    "\n",
    "# Make the initial request to get the page content\n",
    "response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Define the table class to locate the relevant data\n",
    "soup.find_all(class_='responsive-table')\n",
    "\n",
    "# Extract available dates from the dropdown menu\n",
    "select = soup.find(\"select\", {\"name\": \"datum\"})\n",
    "options = select.find_all(\"option\") if select else soup.find_all(\"option\")\n",
    "\n",
    "dates = [opt.get(\"value\") for opt in options if opt.get(\"value\")]\n",
    "\n",
    "# Filter dates for December only\n",
    "selected_dates = [\n",
    "    f for f in dates\n",
    "    if datetime.strptime(f, \"%Y-%m-%d\").month == 12\n",
    "]\n",
    "\n",
    "# Construct URLs for each selected date\n",
    "web_urls = [\n",
    "    f'https://www.transfermarkt.es/statistik/weltrangliste/statistik/stat/ajax/yw1/datum/{date}/plus/0/galerie/0'\n",
    "for date in selected_dates\n",
    "]\n",
    "\n",
    "# Generate paginated URLs\n",
    "pages = []\n",
    "\n",
    "for url in web_urls:\n",
    "    for pag in range(1, 8):\n",
    "        pages.append(f'{url}/page/{pag}')\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "years = []\n",
    "positions = []\n",
    "countries = []\n",
    "confeds = []\n",
    "points = []\n",
    "\n",
    "# Loop through each page and extract the relevant data\n",
    "for page in pages:\n",
    "    resp = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "    for row in soup.find_all(\"tr\"):\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) >= 4:\n",
    "            years.append(page.split(\"/datum/\")[1].split(\"-\")[0])\n",
    "            positions.append(tds[0].get_text(strip=True))\n",
    "            countries.append(tds[1].get_text(strip=True))\n",
    "            confeds.append(tds[2].get_text(strip=True))\n",
    "            points.append(tds[3].get_text(strip=True))\n",
    "\n",
    "# Additionally, extract data for the year 2022\n",
    "urls2022 = [\n",
    "    f'https://www.transfermarkt.es/statistik/weltrangliste/statistik/stat/ajax/yw1/datum/2022-10-06/plus/0/galerie/0/page/{pag}'\n",
    "    for pag in range(1, 8)\n",
    "]\n",
    "for page in urls2022:\n",
    "    resp = requests.get(page, headers=headers)\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "    for row in soup.find_all(\"tr\"):\n",
    "        tds = row.find_all(\"td\")\n",
    "        if len(tds) >= 4:\n",
    "            years.append('2022')\n",
    "            positions.append(tds[0].get_text(strip=True))\n",
    "            countries.append(tds[1].get_text(strip=True))\n",
    "            confeds.append(tds[2].get_text(strip=True))\n",
    "            points.append(tds[3].get_text(strip=True))\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "fifa = pd.DataFrame({\n",
    "    'Year': years,\n",
    "    'Position': positions,\n",
    "    'Country': countries,\n",
    "    'Confederation': confeds,\n",
    "    'Points': points\n",
    "    })\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "project_dir = os.getcwd()\n",
    "csv_route = os.path.join(project_dir, \"fifa_ranking.csv\")\n",
    "fifa.to_csv(csv_route, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd49a077",
   "metadata": {},
   "source": [
    "Scrapping data - Historical worldwide PIB by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b020ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1. Cargar dataset mundial de PIB\n",
    "# ---------------------------\n",
    "url = \"https://raw.githubusercontent.com/datasets/gdp/master/data/gdp.csv\"\n",
    "pib = pd.read_csv(url)\n",
    "# ---------------------------\n",
    "# 2. Conversión de USD a EUR\n",
    "# ---------------------------\n",
    "# Definimos un tipo de cambio aproximado actual\n",
    "usd_to_eur = 0.93  # ajusta según convenga\n",
    "# Creamos columna con PIB en euros\n",
    "pib['Value_EUR'] = pib['Value'] * usd_to_eur\n",
    "# Y en billones de euros (para más fácil lectura)\n",
    "pib['Value_EUR_billions'] = pib['Value_EUR'] / 1e9\n",
    "# ---------------------------\n",
    "# 3. Guardar CSV limpio\n",
    "# ---------------------------\n",
    "# Guardar en la misma carpeta que el script\n",
    "project_dir = os.getcwd()\n",
    "csv_route = os.path.join(project_dir, \"pib_mundial.csv\")\n",
    "pib.to_csv(csv_route, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4891e1f4",
   "metadata": {},
   "source": [
    "Unified dataset - Transforming and merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79447a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for each file\n",
    "fifa = pd.read_csv('fifa_ranking.csv')\n",
    "pib = pd.read_csv('pib_mundial.csv')\n",
    "countries = pd.read_csv('countries.csv')\n",
    "\n",
    "# Renaming columns for merging\n",
    "fifa = fifa.rename(columns={'Country':'Country_ESP'})\n",
    "pib = pib.rename(columns={'Country Name':'Country_ENG'})\n",
    "countries = countries.rename(columns={' name':'Country_ENG', 'nombre':'Country_ESP', ' iso3':'iso3', ' nom':'Country_FRA'})\n",
    "\n",
    "# Replacing country names in fifa to match those in countries.csv\n",
    "countries_replacements = {\n",
    "    'Tunez': 'Túnez',\n",
    "    'Reino Unido': 'Inglaterra',\n",
    "    'Estados Unidos de América': 'Estados Unidos',\n",
    "    'Qatar': 'Catar',\n",
    "    'Islas Bermudas': 'Bermudas',\n",
    "    'Emiratos Árabes Unidos': 'EAU',\n",
    "    'Trinidad y Tobago': 'Trinidad',\n",
    "    'Mali': 'Malí',\n",
    "    'Malawi': 'Malaui',\n",
    "    'Bahrein': 'Baréin',\n",
    "    'República del Congo': 'Congo',\n",
    "    'Surinám': 'Surinam',\n",
    "    'Niger': 'Níger',\n",
    "    'San Vicente y las Granadinas': 'San Vicente',\n",
    "    'Antigua y Barbuda': 'Antigua y Barb.',\n",
    "    'Guinea-Bissau': 'Guinea-Bisáu',\n",
    "    'Hong kong': 'Hong Kong',\n",
    "    'Bangladesh': 'Bangladés',\n",
    "    'República Dominicana': 'Rep. Dominicana',\n",
    "    'República Centroafricana': 'Centroáfrica',\n",
    "    'Guinea Ecuatorial': 'Guinea Ecuat.',\n",
    "    'Birmania': 'Myanmar',\n",
    "    'Islas Maldivas': 'Maldivas',\n",
    "    'Sri lanka': 'Sri Lanka',\n",
    "    'San Cristóbal y Nieves': 'St. Kitts/Nevis',\n",
    "    'República Checa': 'Chequia',\n",
    "    'Macedônia': 'Macedonia Norte',\n",
    "    'Bosnia y Herzegovina': 'Bosnia',\n",
    "    'Papúa Nueva Guinea': 'Papúa N. Guinea',\n",
    "    'República Democrática del Congo': 'RD Congo',\n",
    "    'Islas Vírgenes Británicas': 'Vírgenes B.',\n",
    "    'Islas Turcas y Caicos': 'Turcas y Caicos',\n",
    "    'Santo Tomé y Príncipe': 'Santo Tomé y P.',\n",
    "    'República de Sudán del Sur': 'Sudán del Sur',\n",
    "    'Samoa Americana': 'Samoa A.',\n",
    "    'Islas Vírgenes de los Estados Unidos': 'Vírgenes A.'\n",
    "}\n",
    "countries['Country_ESP'] = countries['Country_ESP'].replace(countries_replacements)\n",
    "\n",
    "# Merging fifa and country code datasets\n",
    "fifa = pd.merge(\n",
    "    fifa,\n",
    "    countries[['Country_ESP', 'iso3']],\n",
    "    on='Country_ESP',\n",
    "    how='left'\n",
    "    )\n",
    "\n",
    "# Renaming columns for merging\n",
    "pib = pib.rename(columns={'Country Code':'iso3'})\n",
    "\n",
    "# Final merge\n",
    "fifa_pib = pd.merge(\n",
    "    fifa,\n",
    "    pib,\n",
    "    on=['iso3', 'Year'],\n",
    "    how='left'\n",
    "    )\n",
    "\n",
    "# Removing rows with missing iso3 codes\n",
    "fifa_pib = fifa_pib[fifa_pib['iso3'].notna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
